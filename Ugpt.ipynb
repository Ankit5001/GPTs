{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\" #Title: The Chronicles of Terra\n",
    "\n",
    "Chapter 1: The Awakening In the year 3025, the planet Terra had become a thriving hub of advanced technology and interstellar travel. Amidst this bustling world, a young engineer named Aria discovered an ancient artifact that would change her life forever.\n",
    "\n",
    "Chapter 2: The Mysterious Artifact The artifact, a small, glowing sphere, seemed to pulse with energy. Aria couldn't decipher its origin, but she knew it held immense power. She decided to seek out the help of Dr. Lumin, an expert in ancient civilizations.\n",
    "\n",
    "Chapter 3: Dr. Lumin's Laboratory Dr. Lumin was fascinated by the artifact and revealed that it was a relic from a long-lost civilization. \"This sphere is a key to unlocking hidden knowledge,\" he explained. Together, they embarked on a quest to uncover its secrets.\n",
    "\n",
    "Chapter 4: Journey to the Desert Their journey led them to the vast deserts of Terra, where the ancient civilization once thrived. As they navigated the treacherous terrain, they encountered mysterious symbols and hidden passages.\n",
    "\n",
    "Chapter 5: The Guardian's Test At the heart of the desert, they discovered a hidden temple guarded by a formidable sentinel. \"To proceed, you must prove your worth,\" the guardian declared. Aria and Dr. Lumin faced a series of challenges, testing their intellect and bravery. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = len(txt) # no of  training tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating token id \n",
    "\n",
    "vocab = \"\".join(sorted(list(set(txt))))\n",
    "vocab_size = len(vocab)\n",
    "stoi = {v:i for i,v in enumerate(vocab)}\n",
    "\n",
    "itos = {i:v for i,v in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = lambda text: [stoi[s] for s in text]\n",
    "decoder = lambda tokens: \"\".join([itos[i] for i in tokens])\n",
    "\n",
    "decoder(encoder('hi fwwwwejw bcvwcb vtheredfwr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(\"#\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder([23,32,12,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = 8\n",
    "embed_dim = 64\n",
    "\n",
    "encoded_txt = encoder(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "    sample = torch.randint(0, total_tokens - block, (1,))\n",
    "    x_block = encoded_txt[sample:sample + block]  # Extract input block\n",
    "    y_block = encoded_txt[sample + 1:sample + block + 1] # Extract target block (shifted by 1)\n",
    "\n",
    "    # Reshape both x and y to be (1, block_size) - batch size of 1 for simplicity here\n",
    "    batch_x = torch.tensor(x_block).unsqueeze(0) # Shape: [1, block]\n",
    "    batch_y = torch.tensor(y_block).unsqueeze(0) # Shape: [1, block]\n",
    "\n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch1(): \n",
    "    sample = torch.randint(0,total_tokens - block, (1,))\n",
    "    x = [encoded_txt[sample+i]  for i in range(block)]\n",
    "    y = [encoded_txt[sample+i+1]  for i in range(block)]\n",
    "    batch_x = []\n",
    "\n",
    "    #print('Word ==>',decoder(x))\n",
    "    \n",
    "    for batch in range(1,block+1):\n",
    "        row = [3]*(block-batch) + x[:batch]\n",
    "        batch_x.append(row )\n",
    "\n",
    "        #print(decoder(row),\"==>\", decoder([y[batch-1]]))\n",
    "    \n",
    "    return torch.tensor(batch_x),torch.tensor(y)\n",
    "\n",
    "\n",
    "get_batch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = torch.randint(0,total_tokens - block, (1,))\n",
    "sample\n",
    "\n",
    "x = torch.tensor([encoded_txt[sample+i]  for i in range(block)])\n",
    "y = torch.tensor([encoded_txt[sample+i+1]  for i in range(block)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_emb(seq,model_dim ):\n",
    "    pos_vec = torch.zeros(size=(seq,model_dim))\n",
    "    for pos in range(seq):\n",
    "        for i in range(0,model_dim,2):\n",
    "            val = torch.tensor(pos/((10000)**(2*i/model_dim)))\n",
    "            pos_vec[pos,i] = torch.sin(val)\n",
    "            pos_vec[pos,i+1] = torch.cos(val)\n",
    "    return pos_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos_digram = pos_emb(block,embed_dim)[3]\n",
    "plt.plot(pos_digram)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tok_emb = nn.Embedding(vocab_size,embed_dim)\n",
    "input_embed = tok_emb(x)\n",
    "position_embedd = pos_emb(block,embed_dim)\n",
    "\n",
    "position_aware_embed = input_embed + position_embedd\n",
    "position_aware_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,embed_dim): # (6,6,32)\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=False) # 32,32,\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=False) # 32,32\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=False) # 32, 32\n",
    "\n",
    "         # (6,6, 32)\n",
    "    def forward(self, position_aware_embed):\n",
    "        key_mat = self.key(position_aware_embed) # 6,6,32\n",
    "        query_mat = self.query(position_aware_embed) #(6,6,32)\n",
    "        value_mat = self.value(position_aware_embed) # (6,6,32)\n",
    "\n",
    "        # Attantion layer\n",
    "        attention = (query_mat @ key_mat.transpose(-1,-2))/(embed_dim**0.5) # (6,6,6)\n",
    "        wei = attention.masked_fill(torch.tril(attention) == 0 , -torch.inf) # (6,6,6)\n",
    "        wei = F.softmax(wei , dim=-1) \n",
    "\n",
    "        return wei @ value_mat #(6,6,32)\n",
    "        #context_aware_emb \n",
    "head = Head(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(embed_dim , 128) # 32,128\n",
    "        self.logit = nn.Linear(128,vocab_size) # 128,32\n",
    "\n",
    "    def forward(self, x): # x=(6,6,32)\n",
    "        x =  F.relu(self.l1(x)) # 6,6,128\n",
    "        x = self.logit(x) # 6,6,128\n",
    "        return F.softmax(x,dim=-1) # 6,6,32\n",
    "    \n",
    "projection = feedForward()\n",
    "logit = projection(head(position_aware_embed))\n",
    "id = torch.argmax(logit,dim=1)\n",
    "id.tolist(),logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "plt.imshow(np.array(list(head.parameters())[0].detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = Head(embed_dim)\n",
    "projection = feedForward()\n",
    "\n",
    "optim_dense = torch.optim.AdamW((list(head.parameters()) + list(projection.parameters()) + list(tok_emb.parameters())), lr=0.1)\n",
    "\n",
    "def train(epochs=100,lr =0.1):\n",
    "\n",
    "    for i in range(epochs):\n",
    "        sample = torch.randint(0, total_tokens - block, (1,))\n",
    "\n",
    "        x, targets = get_batch() # torch.Size([1, 6]) torch.Size([1, 6])\n",
    "\n",
    "        input_embed = tok_emb(x)  #torch.Size([1, 6, 32])\n",
    "        position_embedd = pos_emb(block,embed_dim)  #torch.Size([6, 32]) # Corrected pos_emb input\n",
    "        position_embedd = position_embedd.unsqueeze(0).expand(-1, block, -1) # Corrected pos_emb shape #torch.Size([1, 6, 32])\n",
    "\n",
    "        position_aware_embed = input_embed + position_embedd  #torch.Size([1, 6, 32])\n",
    "\n",
    "        #forward pass\n",
    "        head_out = head(position_aware_embed) # 1,6,32\n",
    "\n",
    "        logits = projection(head_out) # 1,6,vocab_size\n",
    "\n",
    "\n",
    "        logits_flattened = logits.view(-1, logits.size(-1))  # Shape: [6, vocab_size]\n",
    "\n",
    "        # Flatten targets to match the logits\n",
    "        targets_flattened = targets.view(-1) # Shape: [6]\n",
    "\n",
    "        # Compute cross-entropy loss\n",
    "        loss = F.cross_entropy(logits_flattened, targets_flattened)\n",
    "\n",
    "        # backward and optimize\n",
    "        optim_dense.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_dense.step()\n",
    "\n",
    "        if i %100 == 0:\n",
    "            print(i,\"loss :==>\",loss)\n",
    "train(epochs=1000,lr = 0.0003)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start_ids, max_tokens=100, temperature=1.0):  # Added temperature\n",
    "    generated_ids = start_ids # Keep track of generated IDs\n",
    "    new_txt = decoder(torch.tensor(start_ids)) # Decode initial sequence\n",
    "\n",
    "    for i in range(max_tokens):\n",
    "        input_embed = tok_emb(torch.tensor([start_ids]))  # Embed the entire current sequence\n",
    "\n",
    "        # Correct position embedding\n",
    "        positions = torch.arange(len(start_ids), device=input_embed.device)  # Positions for current sequence\n",
    "        position_embedd = pos_emb(positions) # No need for block, pos_emb should handle sequence lengths.\n",
    "        position_aware_embed = input_embed + position_embedd\n",
    "\n",
    "        head_out = head(position_aware_embed)\n",
    "        logits = projection(head_out[:, -1, :])  # Get logits for the last token only\n",
    "\n",
    "        # Temperature/Sampling\n",
    "        if temperature > 0:\n",
    "            probabilities = torch.softmax(logits / temperature, dim=-1)\n",
    "            next_token = torch.multinomial(probabilities, num_samples=1).item()\n",
    "        else:\n",
    "            next_token = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "        generated_ids.append(next_token)  # Add the new token ID\n",
    "        start_ids.append(next_token) # Add the new token to the sequence for the next input.\n",
    "        new_txt = decoder(torch.tensor(generated_ids)) # Decode the whole sequence.\n",
    "\n",
    "    return new_txt\n",
    "generate([0,1,2,3,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
